"""
Parser Finale - Output dataset content with emptied assistant responses.

This parser processes dataset records (JSONL, JSON, or Parquet), emptying
assistant message content while preserving the conversation structure,
tool_calls, system prompts, user messages, tools, and metadata.

Supported Input Formats:
    - JSONL (.jsonl): One JSON object per line
    - JSON (.json): Array of JSON objects
    - Parquet (.parquet, .pq): Apache Parquet columnar format

Supported Output Formats:
    - jsonl: One JSON object per line
    - json: JSON array
    - parquet: Apache Parquet format
    - markdown: Human-readable Markdown
    - text: Plain text summary

Usage:
    uv run python -m scripts.parser_finale dataset/interactive_agent.jsonl
    uv run python -m scripts.parser_finale dataset/data.parquet --output-format jsonl
    uv run python -m scripts.parser_finale dataset/interactive_agent.jsonl -f markdown
    uv run python -m scripts.parser_finale dataset/interactive_agent.jsonl -i 5 -o output.json
"""

from __future__ import annotations

import argparse
import json
import sys
from typing import Any, Iterator

import pyarrow as pa
import pyarrow.parquet as pq

from scripts.data_formats import get_loader, get_loader_for_format, normalize_record


def process_messages(messages: list[dict[str, Any]]) -> list[dict[str, Any]]:
    """
    Process messages, emptying assistant message content while preserving structure.

    Args:
        messages: List of message dictionaries

    Returns:
        List with assistant messages having empty content (structure and tool_calls preserved)
    """
    result = []
    for msg in messages:
        if msg.get("role") == "assistant":
            # Keep assistant message but empty the content
            processed_msg = {"role": "assistant", "content": ""}
            # Preserve tool_calls as-is if present
            if "tool_calls" in msg:
                processed_msg["tool_calls"] = msg["tool_calls"]
            # Preserve reasoning_content as empty string if present
            if "reasoning_content" in msg:
                processed_msg["reasoning_content"] = ""
            result.append(processed_msg)
        else:
            # Keep other messages as-is
            result.append(msg)
    return result


def process_record(record: dict[str, Any]) -> dict[str, Any]:
    """
    Process a single record, emptying assistant message content.

    Args:
        record: Full JSONL record

    Returns:
        Record with assistant message content emptied (structure preserved)
    """
    processed: dict[str, Any] = {
        "uuid": record.get("uuid"),
        "messages": process_messages(record.get("messages", [])),
        "tools": record.get("tools", []),
        "license": record.get("license"),
        "used_in": record.get("used_in", []),
    }

    # Include reasoning flag if present
    if "reasoning" in record:
        processed["reasoning"] = record["reasoning"]

    return processed


def format_json(record: dict[str, Any], pretty: bool = True) -> str:
    """Format record as JSON."""
    if pretty:
        return json.dumps(record, indent=2, ensure_ascii=False)
    return json.dumps(record, ensure_ascii=False)


def format_jsonl(record: dict[str, Any]) -> str:
    """Format record as single JSONL line."""
    return json.dumps(record, ensure_ascii=False)


def format_markdown(record: dict[str, Any]) -> str:
    """Format record as human-readable Markdown."""
    lines: list[str] = []
    lines.append(f"# Record: {record['uuid']}")
    lines.append("")

    # Metadata
    lines.append("## Metadata")
    lines.append(f"- **License:** {record['license']}")
    lines.append(f"- **Used In:** {', '.join(record['used_in'])}")
    if record.get('reasoning'):
        lines.append(f"- **Reasoning:** {record['reasoning']}")
    lines.append("")

    # Messages
    lines.append("## Messages")
    for i, msg in enumerate(record['messages']):
        role = msg.get('role', 'unknown')
        content = msg.get('content', '')
        lines.append(f"### [{i}] {role.upper()}")
        if isinstance(content, dict):
            lines.append("```json")
            lines.append(json.dumps(content, indent=2))
            lines.append("```")
        else:
            lines.append(content if content else "(empty)")
        lines.append("")

    # Tools
    lines.append("## Tools")
    for tool in record['tools']:
        func = tool.get('function', tool)
        name = func.get('name', 'unknown')
        desc = func.get('description', 'No description')
        lines.append(f"### {name}")
        lines.append(f"{desc}")
        lines.append("")

    return "\n".join(lines)


def format_text(record: dict[str, Any]) -> str:
    """Format record as plain text summary."""
    lines: list[str] = []
    lines.append(f"=== Record: {record['uuid']} ===")
    lines.append(f"License: {record['license']}")
    lines.append(f"Used In: {', '.join(record['used_in'])}")
    lines.append(f"Messages: {len(record['messages'])} (assistant content emptied)")
    lines.append(f"Tools: {len(record['tools'])}")
    lines.append("")

    lines.append("--- Messages ---")
    for i, msg in enumerate(record['messages']):
        role = msg.get('role', 'unknown').upper()
        content = msg.get('content', '')
        if isinstance(content, dict):
            content = json.dumps(content)
        content_str = str(content) if content else ""
        preview = content_str[:100] + "..." if len(content_str) > 100 else content_str
        lines.append(f"[{i}] {role}: {preview}")
    lines.append("")

    lines.append("--- Tools ---")
    for tool in record['tools']:
        func = tool.get('function', tool)
        name = func.get('name', 'unknown')
        lines.append(f"  - {name}")

    return "\n".join(lines)


def load_jsonl(filename: str) -> Iterator[dict[str, Any]]:
    """Lazily load records from JSONL file.

    Note: This function is kept for backward compatibility.
    For multi-format support, use load_records() instead.
    """
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                yield json.loads(line)


def load_records(
    filename: str,
    input_format: str = "auto",
    normalize: bool = True,
) -> Iterator[dict[str, Any]]:
    """Load records from any supported file format.

    Args:
        filename: Path to the data file.
        input_format: Format hint ('auto', 'jsonl', 'json', 'parquet').
        normalize: Whether to normalize records to standard schema.

    Yields:
        Each record as a dictionary.
    """
    if input_format == "auto":
        loader = get_loader(filename)
    else:
        loader = get_loader_for_format(input_format)

    for record in loader.load(filename):
        if normalize:
            yield normalize_record(record, loader.format_name)
        else:
            yield record


def write_parquet(records: list[dict[str, Any]], output_file: str) -> None:
    """Write processed records to Parquet format.

    Args:
        records: List of processed records.
        output_file: Path to output file.
    """
    if not records:
        # Create empty parquet file with minimal schema
        table = pa.table({"_empty": []})
        pq.write_table(table, output_file)
        return

    table = pa.Table.from_pylist(records)
    pq.write_table(table, output_file)


def write_json_array(
    records: list[dict[str, Any]],
    output_file: str,
    pretty: bool = True,
) -> None:
    """Write processed records to JSON array format.

    Args:
        records: List of processed records.
        output_file: Path to output file.
        pretty: Whether to use pretty printing with indentation.
    """
    indent = 2 if pretty else None
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(records, f, indent=indent, ensure_ascii=False)


def main() -> None:
    """Main entry point for parser_finale."""
    parser = argparse.ArgumentParser(
        description="Parse datasets and output content with emptied assistant responses. "
        "Supports JSONL, JSON, and Parquet input/output formats."
    )
    parser.add_argument("filename", help="Path to data file (JSONL, JSON, or Parquet)")
    parser.add_argument(
        "--input-format",
        choices=["auto", "jsonl", "json", "parquet"],
        default="auto",
        help="Input file format (default: auto-detect from extension)"
    )
    parser.add_argument(
        "-f", "--format", "--output-format",
        dest="output_format",
        choices=["json", "jsonl", "parquet", "markdown", "text"],
        default="json",
        help="Output format (default: json)"
    )
    parser.add_argument(
        "-o", "--output",
        help="Output file (default: stdout)"
    )
    parser.add_argument(
        "-i", "--index",
        type=int,
        help="Process only record at this index"
    )
    parser.add_argument(
        "--start",
        type=int,
        default=0,
        help="Start index for range processing"
    )
    parser.add_argument(
        "--end",
        type=int,
        help="End index for range processing"
    )
    parser.add_argument(
        "--has-tools",
        action="store_true",
        help="Only include records with tools"
    )
    parser.add_argument(
        "--compact",
        action="store_true",
        help="Compact JSON output (no indentation)"
    )

    args = parser.parse_args()

    # Verify file exists
    import os
    if not os.path.exists(args.filename):
        print(f"Error: File not found: {args.filename}", file=sys.stderr)
        sys.exit(1)

    # Parquet output requires an output file
    if args.output_format == "parquet" and not args.output:
        print("Error: Parquet output requires -o/--output file", file=sys.stderr)
        sys.exit(1)

    # Determine output destination (not used for parquet)
    output_file = None
    output = sys.stdout
    if args.output and args.output_format != "parquet":
        output_file = open(args.output, 'w', encoding='utf-8')
        output = output_file

    try:
        # Select formatter (for text-based formats)
        formatters = {
            "json": lambda r: format_json(r, not args.compact),
            "jsonl": format_jsonl,
            "markdown": format_markdown,
            "text": format_text,
        }

        results: list[dict[str, Any]] = []

        # Use format-aware loading
        for idx, record in enumerate(load_records(args.filename, args.input_format)):
            # Apply index filter
            if args.index is not None and idx != args.index:
                continue

            # Apply range filter
            if idx < args.start:
                continue
            if args.end is not None and idx >= args.end:
                break

            # Apply has-tools filter
            if args.has_tools and not record.get('tools'):
                continue

            processed = process_record(record)

            # Stream JSONL output directly
            if args.output_format == "jsonl":
                formatter = formatters["jsonl"]
                print(formatter(processed), file=output)
            else:
                results.append(processed)

        # Output non-streaming formats
        if args.output_format == "parquet":
            # Write to parquet file
            write_parquet(results, args.output)
            print(f"Wrote {len(results)} records to {args.output}", file=sys.stderr)

        elif args.output_format == "json" and results:
            if len(results) == 1:
                formatter = formatters["json"]
                print(formatter(results[0]), file=output)
            else:
                indent = 2 if not args.compact else None
                print(json.dumps(results, indent=indent, ensure_ascii=False), file=output)

        elif args.output_format in ("markdown", "text") and results:
            formatter = formatters[args.output_format]
            for i, result in enumerate(results):
                print(formatter(result), file=output)
                if i < len(results) - 1:
                    print("\n" + "=" * 60 + "\n", file=output)

    finally:
        if output_file:
            output_file.close()


if __name__ == "__main__":
    main()
